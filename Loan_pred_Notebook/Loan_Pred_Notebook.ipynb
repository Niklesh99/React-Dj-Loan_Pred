{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train_Loan_Home.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnX = data.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnY = data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCol=['Gender','Married','Education','Self_Employed','Property_Area','Dependents']\n",
    "numWithScalingCol=['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\n",
    "numerCol=['Credit_History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer_scaling = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=99))])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('num', numeric_transformer_scaling, numWithScalingCol),\n",
    "    ('num2', numeric_transformer, numerCol),\n",
    "    ('cat', categorical_transformer, catCol)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ensemble.RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['ApplicantIncome',\n",
       "                                                   'CoapplicantIncome',\n",
       "                                                   'LoanAmount',\n",
       "                                                   'Loan_Amount_Term']),\n",
       "                                                 ('num2',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=99,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  ['Credit_History']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Gender', 'Married',\n",
       "                                                   'Education', 'Self_Employed',\n",
       "                                                   'Property_Area',\n",
       "                                                   'Dependents'])])),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPipeline.fit(data[columnX], data[columnY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = modelPipeline.predict_proba(data[columnX])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99, 0.28, 0.89, 0.97, 0.99, 0.9 , 0.93, 0.09, 0.93, 0.18, 0.98,\n",
       "       0.94, 0.93, 0.31, 0.86, 0.93, 0.87, 0.02, 0.3 , 0.96, 0.06, 0.92,\n",
       "       0.05, 0.05, 0.34, 0.94, 0.98, 0.96, 0.19, 0.96, 0.24, 0.27, 0.3 ,\n",
       "       1.  , 0.16, 1.  , 0.04, 0.99, 0.81, 0.97, 0.2 , 0.89, 0.92, 0.96,\n",
       "       0.81, 0.92, 0.85, 0.96, 0.04, 0.91, 0.98, 0.98, 0.32, 0.28, 0.13,\n",
       "       0.99, 0.98, 0.33, 0.96, 0.94, 0.95, 0.88, 0.12, 0.1 , 0.04, 0.32,\n",
       "       0.09, 0.88, 0.81, 0.04, 0.89, 0.97, 0.9 , 0.14, 0.92, 0.27, 0.31,\n",
       "       0.19, 0.09, 0.9 , 0.92, 0.98, 0.18, 0.18, 0.85, 0.96, 0.99, 1.  ,\n",
       "       0.82, 0.97, 0.98, 0.94, 0.99, 0.9 , 0.9 , 0.27, 0.99, 0.94, 0.93,\n",
       "       0.95, 0.87, 0.91, 0.97, 0.98, 0.88, 0.97, 0.95, 0.27, 0.08, 0.89,\n",
       "       0.99, 0.98, 0.03, 0.96, 0.96, 0.88, 0.97, 0.91, 0.21, 0.74, 0.82,\n",
       "       0.95, 0.78, 0.97, 0.84, 0.94, 0.87, 0.98, 0.13, 0.25, 0.67, 0.78,\n",
       "       0.99, 0.94, 0.89, 0.17, 0.12, 0.94, 0.12, 0.33, 0.3 , 0.97, 0.92,\n",
       "       1.  , 0.96, 0.96, 0.83, 0.92, 0.17, 0.99, 0.03, 0.98, 0.24, 0.37,\n",
       "       0.96, 0.67, 0.86, 0.95, 0.89, 0.86, 0.99, 0.34, 0.05, 0.87, 0.94,\n",
       "       0.83, 0.17, 0.99, 0.05, 0.97, 0.94, 0.93, 0.2 , 0.95, 0.31, 0.93,\n",
       "       0.96, 0.11, 0.99, 0.03, 0.17, 0.31, 0.93, 0.37, 0.97, 0.97, 0.08,\n",
       "       0.92, 0.84, 0.96, 0.87, 0.25, 0.24, 0.96, 0.95, 0.44, 0.84, 0.86,\n",
       "       0.95, 0.3 , 0.96, 0.8 , 0.35, 0.96, 0.96, 0.93, 0.94, 0.83, 0.92,\n",
       "       0.32, 0.32, 0.08, 0.92, 0.84, 0.96, 0.98, 0.34, 0.98, 0.11, 0.95,\n",
       "       0.09, 0.98, 0.97, 0.86, 0.87, 0.36, 0.37, 0.96, 0.86, 0.85, 1.  ,\n",
       "       0.83, 0.88, 0.76, 0.95, 0.86, 0.29, 0.96, 0.87, 1.  , 0.94, 0.29,\n",
       "       0.8 , 0.98, 0.94, 0.44, 0.89, 0.88, 0.93, 0.98, 0.03, 0.31, 0.86,\n",
       "       0.74, 0.06, 0.87, 0.05, 0.28, 0.24, 0.37, 0.85, 0.91, 0.3 , 0.92,\n",
       "       0.94, 1.  , 0.98, 0.7 , 0.27, 0.92, 0.92, 0.88, 0.93, 0.99, 0.97,\n",
       "       0.96, 0.98, 0.97, 0.85, 0.93, 0.06, 0.99, 0.96, 0.91, 0.33, 0.87,\n",
       "       0.37, 0.97, 0.92, 0.89, 0.93, 0.12, 0.92, 0.1 , 1.  , 0.92, 0.99,\n",
       "       0.78, 0.36, 0.3 , 0.05, 0.91, 0.96, 0.88, 0.95, 0.21, 0.86, 0.04,\n",
       "       0.16, 0.9 , 0.99, 0.98, 0.87, 0.89, 0.3 , 0.92, 0.99, 0.98, 0.89,\n",
       "       0.26, 1.  , 0.93, 0.75, 0.88, 0.9 , 0.04, 0.72, 0.95, 0.19, 0.92,\n",
       "       0.93, 0.94, 0.79, 0.89, 0.89, 0.93, 0.85, 0.95, 0.05, 0.97, 0.31,\n",
       "       0.33, 0.92, 0.83, 0.94, 0.98, 0.03, 0.99, 0.72, 0.95, 0.89, 0.19,\n",
       "       0.91, 0.09, 1.  , 0.92, 0.89, 0.23, 0.05, 0.9 , 0.33, 0.95, 0.9 ,\n",
       "       0.97, 0.93, 0.21, 0.32, 0.13, 0.96, 0.24, 0.89, 0.97, 0.98, 0.11,\n",
       "       0.96, 0.98, 0.91, 0.93, 0.19, 0.84, 0.94, 0.87, 0.95, 0.83, 0.26,\n",
       "       0.86, 0.92, 0.05, 0.96, 0.83, 0.94, 0.94, 0.99, 0.95, 0.94, 0.94,\n",
       "       0.03, 1.  , 0.98, 0.12, 0.12, 0.21, 0.92, 0.96, 0.28, 0.73, 0.95,\n",
       "       0.79, 0.09, 0.14, 0.34, 0.77, 0.1 , 0.99, 0.07, 0.98, 0.37, 0.24,\n",
       "       0.91, 0.99, 0.9 , 0.03, 0.97, 0.06, 0.96, 0.95, 0.24, 0.96, 0.87,\n",
       "       0.73, 0.93, 0.03, 0.87, 1.  , 0.79, 0.92, 0.89, 0.98, 0.06, 0.82,\n",
       "       0.92, 0.84, 0.86, 0.73, 0.8 , 0.84, 0.77, 0.31, 0.03, 0.2 , 0.07,\n",
       "       0.88, 0.03, 0.65, 0.93, 0.99, 0.88, 0.21, 0.82, 0.3 , 0.93, 0.94,\n",
       "       0.96, 0.89, 0.07, 0.96, 0.12, 0.97, 0.84, 0.33, 0.96, 0.07, 0.95,\n",
       "       0.96, 0.91, 0.9 , 0.94, 0.08, 0.99, 0.43, 0.79, 0.83, 0.98, 0.94,\n",
       "       0.95, 0.93, 0.05, 0.33, 0.9 , 0.24, 0.93, 0.89, 0.94, 0.91, 0.08,\n",
       "       0.96, 0.92, 0.93, 0.98, 0.12, 0.84, 0.99, 1.  , 0.24, 0.96, 0.89,\n",
       "       0.88, 0.31, 0.91, 0.88, 0.39, 0.89, 0.99, 0.41, 0.25, 0.91, 0.91,\n",
       "       0.04, 0.17, 0.34, 0.97, 0.98, 0.98, 0.93, 0.27, 0.86, 0.99, 0.66,\n",
       "       0.95, 0.9 , 0.85, 0.85, 0.06, 0.2 , 0.87, 0.94, 0.91, 0.92, 0.3 ,\n",
       "       0.94, 0.89, 0.08, 0.92, 0.91, 0.98, 0.97, 0.26, 0.95, 0.03, 0.99,\n",
       "       0.08, 0.94, 0.89, 0.06, 0.13, 0.96, 0.95, 0.87, 0.97, 0.9 , 1.  ,\n",
       "       0.87, 0.83, 0.9 , 0.16, 0.84, 0.79, 0.12, 0.36, 0.06, 0.92, 0.2 ,\n",
       "       0.87, 0.26, 0.32, 0.96, 0.05, 0.9 , 0.96, 0.92, 0.99, 0.18, 0.97,\n",
       "       0.21, 0.06, 0.27, 0.98, 0.97, 0.84, 0.12, 0.93, 0.31, 0.94, 0.9 ,\n",
       "       0.92, 0.96, 0.27, 0.06, 0.9 , 0.92, 0.17, 0.96, 0.9 , 0.91, 0.79,\n",
       "       0.27, 0.86, 0.73, 0.97, 0.94, 0.87, 0.94, 0.97, 0.05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('Test_Loan_Home.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = modelPipeline.predict_proba(data2[columnX])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9 , 0.9 , 0.81, 0.83, 0.52, 0.61, 0.7 , 0.17, 0.83, 0.96, 0.52,\n",
       "       0.81, 0.77, 0.31, 0.66, 0.86, 0.81, 0.89, 0.75, 0.72, 0.83, 0.55,\n",
       "       0.46, 0.82, 0.72, 0.42, 0.76, 0.74, 0.93, 0.83, 0.96, 0.96, 0.7 ,\n",
       "       0.82, 0.97, 0.19, 0.83, 0.89, 0.81, 0.76, 0.88, 0.88, 0.92, 0.67,\n",
       "       0.84, 0.73, 0.68, 0.94, 0.78, 0.69, 0.79, 0.86, 0.72, 0.94, 0.77,\n",
       "       0.22, 0.78, 0.92, 0.32, 0.87, 0.95, 0.94, 0.59, 0.24, 0.61, 0.99,\n",
       "       0.2 , 0.15, 0.68, 0.28, 0.84, 0.82, 0.76, 0.84, 0.86, 0.71, 0.75,\n",
       "       0.72, 0.75, 0.62, 0.4 , 0.73, 0.16, 0.7 , 0.31, 0.77, 0.82, 0.87,\n",
       "       0.88, 0.41, 0.91, 0.86, 0.83, 0.84, 0.16, 0.74, 0.76, 0.99, 0.61,\n",
       "       0.61, 0.91, 0.24, 0.57, 0.44, 0.89, 0.91, 0.12, 0.79, 0.89, 0.54,\n",
       "       0.69, 0.95, 0.9 , 0.93, 0.75, 0.69, 0.61, 0.35, 0.11, 0.28, 0.68,\n",
       "       0.93, 0.84, 0.33, 0.21, 0.71, 0.08, 0.93, 0.66, 0.87, 0.95, 0.77,\n",
       "       0.8 , 0.73, 0.59, 0.89, 0.71, 0.73, 0.74, 0.9 , 0.61, 0.86, 0.23,\n",
       "       0.69, 0.76, 0.86, 0.77, 0.18, 0.94, 0.99, 0.58, 0.96, 0.95, 0.21,\n",
       "       0.71, 0.64, 0.8 , 0.49, 0.63, 0.36, 0.83, 0.26, 0.95, 0.92, 0.59,\n",
       "       0.2 , 0.15, 0.98, 0.3 , 0.4 , 0.9 , 0.48, 0.86, 0.27, 0.13, 0.77,\n",
       "       0.79, 0.95, 0.76, 0.86, 0.92, 0.91, 0.45, 0.5 , 0.85, 0.74, 0.82,\n",
       "       0.98, 0.35, 0.77, 0.47, 0.74, 0.24, 0.16, 0.55, 0.81, 0.16, 0.86,\n",
       "       0.21, 0.82, 0.71, 0.7 , 0.91, 0.97, 0.86, 1.  , 0.75, 0.88, 0.85,\n",
       "       0.5 , 0.65, 0.25, 0.81, 0.95, 0.8 , 0.78, 0.75, 0.59, 0.73, 0.86,\n",
       "       0.95, 0.7 , 0.55, 0.72, 0.4 , 0.86, 0.98, 0.72, 0.77, 0.19, 0.68,\n",
       "       0.69, 0.72, 0.59, 0.6 , 0.15, 0.26, 0.64, 0.97, 0.31, 0.74, 0.13,\n",
       "       0.99, 0.26, 0.95, 0.22, 0.9 , 0.96, 0.54, 0.7 , 0.34, 0.86, 0.69,\n",
       "       0.87, 0.73, 0.23, 0.39, 0.85, 0.97, 0.56, 0.64, 0.99, 0.69, 0.67,\n",
       "       0.69, 0.83, 0.19, 0.54, 0.24, 0.65, 0.66, 0.53, 0.46, 0.29, 0.13,\n",
       "       0.9 , 0.8 , 0.68, 0.25, 0.5 , 0.86, 0.77, 0.88, 0.4 , 0.57, 0.75,\n",
       "       0.78, 0.67, 0.96, 0.75, 0.88, 0.97, 0.48, 0.1 , 0.68, 0.81, 0.83,\n",
       "       0.51, 0.94, 0.67, 0.75, 0.2 , 0.47, 0.6 , 0.97, 0.64, 0.82, 0.63,\n",
       "       0.8 , 0.92, 0.99, 0.3 , 0.84, 0.73, 0.85, 0.84, 0.41, 0.07, 0.63,\n",
       "       0.85, 0.67, 0.57, 0.76, 0.67, 0.77, 0.29, 0.84, 0.86, 0.91, 0.9 ,\n",
       "       0.88, 0.81, 0.67, 0.8 , 0.85, 0.62, 0.82, 0.98, 0.64, 0.3 , 0.81,\n",
       "       0.86, 0.2 , 0.52, 0.88, 0.73, 0.11, 0.57, 0.91, 0.75, 0.84, 0.6 ,\n",
       "       0.89, 0.79, 0.37, 0.86, 0.77, 0.92, 0.59, 0.86, 0.57, 1.  , 0.82,\n",
       "       0.88, 0.66, 0.5 , 0.53])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreOutput = {j:k for j,k in zip(data2['Loan_ID'],scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LP001015': 0.9,\n",
       " 'LP001022': 0.9,\n",
       " 'LP001031': 0.81,\n",
       " 'LP001035': 0.83,\n",
       " 'LP001051': 0.52,\n",
       " 'LP001054': 0.61,\n",
       " 'LP001055': 0.7,\n",
       " 'LP001056': 0.17,\n",
       " 'LP001059': 0.83,\n",
       " 'LP001067': 0.96,\n",
       " 'LP001078': 0.52,\n",
       " 'LP001082': 0.81,\n",
       " 'LP001083': 0.77,\n",
       " 'LP001094': 0.31,\n",
       " 'LP001096': 0.66,\n",
       " 'LP001099': 0.86,\n",
       " 'LP001105': 0.81,\n",
       " 'LP001107': 0.89,\n",
       " 'LP001108': 0.75,\n",
       " 'LP001115': 0.72,\n",
       " 'LP001121': 0.83,\n",
       " 'LP001124': 0.55,\n",
       " 'LP001128': 0.46,\n",
       " 'LP001135': 0.82,\n",
       " 'LP001149': 0.72,\n",
       " 'LP001153': 0.42,\n",
       " 'LP001163': 0.76,\n",
       " 'LP001169': 0.74,\n",
       " 'LP001174': 0.93,\n",
       " 'LP001176': 0.83,\n",
       " 'LP001177': 0.96,\n",
       " 'LP001183': 0.96,\n",
       " 'LP001185': 0.7,\n",
       " 'LP001187': 0.82,\n",
       " 'LP001190': 0.97,\n",
       " 'LP001203': 0.19,\n",
       " 'LP001208': 0.83,\n",
       " 'LP001210': 0.89,\n",
       " 'LP001211': 0.81,\n",
       " 'LP001219': 0.76,\n",
       " 'LP001220': 0.88,\n",
       " 'LP001221': 0.88,\n",
       " 'LP001226': 0.92,\n",
       " 'LP001230': 0.67,\n",
       " 'LP001231': 0.84,\n",
       " 'LP001232': 0.73,\n",
       " 'LP001237': 0.68,\n",
       " 'LP001242': 0.94,\n",
       " 'LP001268': 0.78,\n",
       " 'LP001270': 0.69,\n",
       " 'LP001284': 0.79,\n",
       " 'LP001287': 0.86,\n",
       " 'LP001291': 0.72,\n",
       " 'LP001298': 0.94,\n",
       " 'LP001312': 0.77,\n",
       " 'LP001313': 0.22,\n",
       " 'LP001317': 0.78,\n",
       " 'LP001321': 0.92,\n",
       " 'LP001323': 0.32,\n",
       " 'LP001324': 0.87,\n",
       " 'LP001332': 0.95,\n",
       " 'LP001335': 0.94,\n",
       " 'LP001338': 0.59,\n",
       " 'LP001347': 0.24,\n",
       " 'LP001348': 0.61,\n",
       " 'LP001351': 0.99,\n",
       " 'LP001352': 0.2,\n",
       " 'LP001358': 0.15,\n",
       " 'LP001359': 0.68,\n",
       " 'LP001361': 0.28,\n",
       " 'LP001366': 0.84,\n",
       " 'LP001368': 0.82,\n",
       " 'LP001375': 0.76,\n",
       " 'LP001380': 0.84,\n",
       " 'LP001386': 0.86,\n",
       " 'LP001400': 0.71,\n",
       " 'LP001407': 0.75,\n",
       " 'LP001413': 0.72,\n",
       " 'LP001415': 0.75,\n",
       " 'LP001419': 0.62,\n",
       " 'LP001420': 0.4,\n",
       " 'LP001428': 0.73,\n",
       " 'LP001445': 0.16,\n",
       " 'LP001446': 0.7,\n",
       " 'LP001450': 0.31,\n",
       " 'LP001452': 0.77,\n",
       " 'LP001455': 0.82,\n",
       " 'LP001466': 0.87,\n",
       " 'LP001471': 0.88,\n",
       " 'LP001472': 0.41,\n",
       " 'LP001475': 0.91,\n",
       " 'LP001483': 0.86,\n",
       " 'LP001486': 0.83,\n",
       " 'LP001490': 0.84,\n",
       " 'LP001496': 0.16,\n",
       " 'LP001499': 0.74,\n",
       " 'LP001500': 0.76,\n",
       " 'LP001501': 0.99,\n",
       " 'LP001517': 0.61,\n",
       " 'LP001527': 0.61,\n",
       " 'LP001534': 0.91,\n",
       " 'LP001542': 0.24,\n",
       " 'LP001547': 0.57,\n",
       " 'LP001548': 0.44,\n",
       " 'LP001558': 0.89,\n",
       " 'LP001561': 0.91,\n",
       " 'LP001563': 0.12,\n",
       " 'LP001567': 0.79,\n",
       " 'LP001568': 0.89,\n",
       " 'LP001573': 0.54,\n",
       " 'LP001584': 0.69,\n",
       " 'LP001587': 0.95,\n",
       " 'LP001589': 0.9,\n",
       " 'LP001591': 0.93,\n",
       " 'LP001599': 0.75,\n",
       " 'LP001601': 0.69,\n",
       " 'LP001607': 0.61,\n",
       " 'LP001611': 0.35,\n",
       " 'LP001613': 0.11,\n",
       " 'LP001622': 0.28,\n",
       " 'LP001627': 0.68,\n",
       " 'LP001650': 0.93,\n",
       " 'LP001651': 0.84,\n",
       " 'LP001652': 0.33,\n",
       " 'LP001655': 0.21,\n",
       " 'LP001660': 0.71,\n",
       " 'LP001662': 0.08,\n",
       " 'LP001663': 0.93,\n",
       " 'LP001667': 0.66,\n",
       " 'LP001695': 0.87,\n",
       " 'LP001703': 0.95,\n",
       " 'LP001718': 0.77,\n",
       " 'LP001728': 0.8,\n",
       " 'LP001735': 0.73,\n",
       " 'LP001737': 0.59,\n",
       " 'LP001739': 0.89,\n",
       " 'LP001742': 0.71,\n",
       " 'LP001757': 0.73,\n",
       " 'LP001769': 0.74,\n",
       " 'LP001771': 0.9,\n",
       " 'LP001785': 0.61,\n",
       " 'LP001787': 0.86,\n",
       " 'LP001789': 0.23,\n",
       " 'LP001791': 0.69,\n",
       " 'LP001794': 0.76,\n",
       " 'LP001797': 0.86,\n",
       " 'LP001815': 0.77,\n",
       " 'LP001817': 0.18,\n",
       " 'LP001818': 0.94,\n",
       " 'LP001822': 0.99,\n",
       " 'LP001827': 0.58,\n",
       " 'LP001831': 0.96,\n",
       " 'LP001842': 0.95,\n",
       " 'LP001853': 0.21,\n",
       " 'LP001855': 0.71,\n",
       " 'LP001857': 0.64,\n",
       " 'LP001862': 0.8,\n",
       " 'LP001867': 0.49,\n",
       " 'LP001878': 0.63,\n",
       " 'LP001881': 0.36,\n",
       " 'LP001886': 0.83,\n",
       " 'LP001906': 0.26,\n",
       " 'LP001909': 0.95,\n",
       " 'LP001911': 0.92,\n",
       " 'LP001921': 0.59,\n",
       " 'LP001923': 0.2,\n",
       " 'LP001933': 0.15,\n",
       " 'LP001943': 0.98,\n",
       " 'LP001950': 0.3,\n",
       " 'LP001959': 0.4,\n",
       " 'LP001961': 0.9,\n",
       " 'LP001973': 0.48,\n",
       " 'LP001975': 0.86,\n",
       " 'LP001979': 0.27,\n",
       " 'LP001995': 0.13,\n",
       " 'LP001999': 0.77,\n",
       " 'LP002007': 0.79,\n",
       " 'LP002009': 0.95,\n",
       " 'LP002016': 0.76,\n",
       " 'LP002017': 0.86,\n",
       " 'LP002018': 0.92,\n",
       " 'LP002027': 0.91,\n",
       " 'LP002028': 0.45,\n",
       " 'LP002042': 0.5,\n",
       " 'LP002045': 0.85,\n",
       " 'LP002046': 0.74,\n",
       " 'LP002047': 0.82,\n",
       " 'LP002056': 0.98,\n",
       " 'LP002057': 0.35,\n",
       " 'LP002059': 0.77,\n",
       " 'LP002062': 0.47,\n",
       " 'LP002064': 0.74,\n",
       " 'LP002069': 0.24,\n",
       " 'LP002070': 0.16,\n",
       " 'LP002077': 0.55,\n",
       " 'LP002083': 0.81,\n",
       " 'LP002090': 0.16,\n",
       " 'LP002096': 0.86,\n",
       " 'LP002099': 0.21,\n",
       " 'LP002102': 0.82,\n",
       " 'LP002105': 0.71,\n",
       " 'LP002107': 0.7,\n",
       " 'LP002111': 0.91,\n",
       " 'LP002117': 0.97,\n",
       " 'LP002118': 0.86,\n",
       " 'LP002123': 1.0,\n",
       " 'LP002125': 0.75,\n",
       " 'LP002148': 0.88,\n",
       " 'LP002152': 0.85,\n",
       " 'LP002165': 0.5,\n",
       " 'LP002167': 0.65,\n",
       " 'LP002168': 0.25,\n",
       " 'LP002172': 0.81,\n",
       " 'LP002176': 0.95,\n",
       " 'LP002183': 0.8,\n",
       " 'LP002184': 0.78,\n",
       " 'LP002186': 0.75,\n",
       " 'LP002192': 0.59,\n",
       " 'LP002195': 0.73,\n",
       " 'LP002208': 0.86,\n",
       " 'LP002212': 0.95,\n",
       " 'LP002240': 0.7,\n",
       " 'LP002245': 0.55,\n",
       " 'LP002253': 0.72,\n",
       " 'LP002256': 0.4,\n",
       " 'LP002257': 0.86,\n",
       " 'LP002264': 0.98,\n",
       " 'LP002270': 0.72,\n",
       " 'LP002279': 0.77,\n",
       " 'LP002286': 0.19,\n",
       " 'LP002294': 0.68,\n",
       " 'LP002298': 0.69,\n",
       " 'LP002306': 0.72,\n",
       " 'LP002310': 0.59,\n",
       " 'LP002311': 0.6,\n",
       " 'LP002316': 0.15,\n",
       " 'LP002321': 0.26,\n",
       " 'LP002325': 0.64,\n",
       " 'LP002326': 0.97,\n",
       " 'LP002329': 0.31,\n",
       " 'LP002333': 0.74,\n",
       " 'LP002339': 0.13,\n",
       " 'LP002344': 0.99,\n",
       " 'LP002346': 0.26,\n",
       " 'LP002354': 0.95,\n",
       " 'LP002355': 0.22,\n",
       " 'LP002358': 0.9,\n",
       " 'LP002360': 0.96,\n",
       " 'LP002375': 0.54,\n",
       " 'LP002376': 0.7,\n",
       " 'LP002383': 0.34,\n",
       " 'LP002385': 0.86,\n",
       " 'LP002389': 0.69,\n",
       " 'LP002394': 0.87,\n",
       " 'LP002397': 0.73,\n",
       " 'LP002399': 0.23,\n",
       " 'LP002400': 0.39,\n",
       " 'LP002402': 0.85,\n",
       " 'LP002412': 0.97,\n",
       " 'LP002415': 0.56,\n",
       " 'LP002417': 0.64,\n",
       " 'LP002420': 0.99,\n",
       " 'LP002425': 0.69,\n",
       " 'LP002433': 0.67,\n",
       " 'LP002440': 0.69,\n",
       " 'LP002441': 0.83,\n",
       " 'LP002442': 0.19,\n",
       " 'LP002445': 0.54,\n",
       " 'LP002450': 0.24,\n",
       " 'LP002471': 0.65,\n",
       " 'LP002476': 0.66,\n",
       " 'LP002482': 0.53,\n",
       " 'LP002485': 0.46,\n",
       " 'LP002495': 0.29,\n",
       " 'LP002496': 0.13,\n",
       " 'LP002523': 0.9,\n",
       " 'LP002542': 0.8,\n",
       " 'LP002550': 0.68,\n",
       " 'LP002551': 0.25,\n",
       " 'LP002553': 0.5,\n",
       " 'LP002554': 0.86,\n",
       " 'LP002561': 0.77,\n",
       " 'LP002566': 0.88,\n",
       " 'LP002568': 0.4,\n",
       " 'LP002570': 0.57,\n",
       " 'LP002572': 0.75,\n",
       " 'LP002581': 0.78,\n",
       " 'LP002584': 0.67,\n",
       " 'LP002592': 0.96,\n",
       " 'LP002593': 0.75,\n",
       " 'LP002599': 0.88,\n",
       " 'LP002604': 0.97,\n",
       " 'LP002605': 0.48,\n",
       " 'LP002609': 0.1,\n",
       " 'LP002610': 0.68,\n",
       " 'LP002612': 0.81,\n",
       " 'LP002614': 0.83,\n",
       " 'LP002630': 0.51,\n",
       " 'LP002635': 0.94,\n",
       " 'LP002639': 0.67,\n",
       " 'LP002644': 0.75,\n",
       " 'LP002651': 0.2,\n",
       " 'LP002654': 0.47,\n",
       " 'LP002657': 0.6,\n",
       " 'LP002711': 0.97,\n",
       " 'LP002712': 0.64,\n",
       " 'LP002721': 0.82,\n",
       " 'LP002735': 0.63,\n",
       " 'LP002744': 0.8,\n",
       " 'LP002745': 0.92,\n",
       " 'LP002746': 0.99,\n",
       " 'LP002747': 0.3,\n",
       " 'LP002754': 0.84,\n",
       " 'LP002759': 0.73,\n",
       " 'LP002760': 0.85,\n",
       " 'LP002766': 0.84,\n",
       " 'LP002769': 0.41,\n",
       " 'LP002774': 0.07,\n",
       " 'LP002775': 0.63,\n",
       " 'LP002781': 0.85,\n",
       " 'LP002782': 0.67,\n",
       " 'LP002786': 0.57,\n",
       " 'LP002790': 0.76,\n",
       " 'LP002791': 0.67,\n",
       " 'LP002793': 0.77,\n",
       " 'LP002802': 0.29,\n",
       " 'LP002803': 0.84,\n",
       " 'LP002805': 0.86,\n",
       " 'LP002806': 0.91,\n",
       " 'LP002816': 0.9,\n",
       " 'LP002823': 0.88,\n",
       " 'LP002825': 0.81,\n",
       " 'LP002826': 0.67,\n",
       " 'LP002843': 0.8,\n",
       " 'LP002849': 0.85,\n",
       " 'LP002850': 0.62,\n",
       " 'LP002853': 0.82,\n",
       " 'LP002856': 0.98,\n",
       " 'LP002857': 0.64,\n",
       " 'LP002858': 0.3,\n",
       " 'LP002860': 0.81,\n",
       " 'LP002867': 0.86,\n",
       " 'LP002869': 0.2,\n",
       " 'LP002870': 0.52,\n",
       " 'LP002876': 0.88,\n",
       " 'LP002878': 0.73,\n",
       " 'LP002879': 0.11,\n",
       " 'LP002885': 0.57,\n",
       " 'LP002890': 0.91,\n",
       " 'LP002891': 0.75,\n",
       " 'LP002899': 0.84,\n",
       " 'LP002901': 0.6,\n",
       " 'LP002907': 0.89,\n",
       " 'LP002920': 0.79,\n",
       " 'LP002921': 0.37,\n",
       " 'LP002932': 0.86,\n",
       " 'LP002935': 0.77,\n",
       " 'LP002952': 0.92,\n",
       " 'LP002954': 0.59,\n",
       " 'LP002962': 0.86,\n",
       " 'LP002965': 0.57,\n",
       " 'LP002969': 1.0,\n",
       " 'LP002971': 0.82,\n",
       " 'LP002975': 0.88,\n",
       " 'LP002980': 0.66,\n",
       " 'LP002986': 0.5,\n",
       " 'LP002989': 0.53}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelPipeline.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(modelPipeline,'modelPipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
